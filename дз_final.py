# -*- coding: utf-8 -*-
"""ДЗ_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kCk4BZHir78tN4yaYaihxmSNUXh07RGG

Задача 1. Загрузка данных в колабу
"""

import pandas as pd

from google.colab import files
uploaded = files.upload()

# Загружаем данные
df = pd.read_csv('HR.csv')

# Смотрим первые строки
df.head()

"""Задача 2. Рассчитайте основные статистики для переменных
(среднее,медиана,мода,мин/макс,сред.отклонение).
"""

#Выбираем признаки с количеством
numeric_columns = ['satisfaction_level', 'last_evaluation', 'number_project', 'average_montly_hours', 'time_spend_company']

#Пишеем основные статистики (средняя, медиана, частота значений, мин, макс, стандарт отклон)
df_stats = pd.DataFrame({'mean': df[numeric_columns].mean(),
                         'median': df[numeric_columns].median(),
                         'mode': df[numeric_columns].mode().iloc[0],
                         'min': df[numeric_columns].min(),
                         'max': df[numeric_columns].max(),
                         'std': df[numeric_columns].std()
                         })
df_stats

#Добавим расширинные статистики (вариация, ассиметрия, эксцесс)
import numpy as np

#Коэф вариации
cv = df[numeric_columns].std() / df[numeric_columns].mean()

#Асимметрия
skewness = df[numeric_columns].skew()

#Эксцесс
kurtosis = df[numeric_columns].kurt()

#Выводим инфу
print("Коэф вариации:\n", cv)
print("\nАсcимметрия:\n", skewness)
print("\nКоэф вариации:\n", kurtosis)

import seaborn as sns
import matplotlib.pyplot as plt

for col in numeric_columns:
    plt.figure(figsize=(10,5))
    sns.histplot(df[col], kde=True, bins=30)
    plt.title(f'Распределение кол-во признаков {col}')
    plt.show()

"""Задача 3. Рассчитайте и визуализировать корреляционную матрицу для
количественных переменных.
Определите две самые скоррелированные и две наименее
скоррелированные переменные.
"""

#корреляционная матрица

plt.figure(figsize=(9,7))
corr = df[numeric_columns].corr()
sns.heatmap(corr, annot=True, cmap = 'coolwarm')
plt.title(f'Распределение кол-во признаков {col}')
plt.show()

#две самые скоррелированные и две наименее скоррелированные переменные

corr_pairs = corr.abs().unstack().sort_values(kind='quicksort', ascending=False)
corr_pairs = corr_pairs[corr_pairs < 1]

print("самые скоррелированные:\n", corr_pairs[:2])
print("\nнаименее скоррелированные переменные:\n", corr_pairs[-2:])

"""Задача 4. Рассчитайте сколько сотрудников работает в каждом
департаменте.
"""

#посчитаем кол-во сотрудников по каждому депу

df['department'].value_counts()

"""Задача 5. Показать распределение сотрудников по зарплатам."""

sns.countplot(x='salary', data=df, order=['low', 'medium', 'high'])
plt.title('распределение сотрудников по зарплатам')
plt.show()

"""Задача 6. Показать распределение сотрудников по зарплатам в каждом
департаменте по отдельности.
"""

plt.figure(figsize=(7,5))
sns.countplot(x='department', hue='salary', data=df, order=df['department'].value_counts().index)
plt.title('распределение сотрудников по зарплатам в каждом департаменте')
plt.xticks(rotation=45)
plt.show()

"""Задача 7. Проверить гипотезу, что сотрудники с высоким окладом
проводят на работе больше времени, чем сотрудники с низким
окладом
"""

from scipy import stats

high_salary_hours = df[df['salary'] == 'high']['average_montly_hours']
low_salary_hours = df[df['salary'] == 'low']['average_montly_hours']

t_stat, p_value = stats.ttest_ind(high_salary_hours, low_salary_hours, equal_var=False)

print("t-stat:", t_stat)
print("\np-value:", p_value)

"""Задача 8. Рассчитать следующие показатели среди уволившихся и не
уволившихся сотрудников (по отдельности):

*   Доля сотрудников с повышением за последние 5 лет
*   Средняя степень удовлетворенности
*   Среднее количество проектов
"""

df.groupby('left').agg({'promotion_last_5years': 'mean',
                        'satisfaction_level': 'mean',
                        'number_project': 'mean'
                        })

#t-test на среднюю степень удовлетворенности и среднее кол-во проектов
satisfaction_left = df[df['left']==1]['satisfaction_level']
satisfaction_stayed = df[df['left']==0]['satisfaction_level']
t_stat_satisfaction, p_val_satisfaction = stats.ttest_ind(satisfaction_left, satisfaction_stayed, equal_var=False)

projects_left = df[df['left']==1]['number_project']
projects_stayed = df[df['left']==0]['number_project']
t_stat_projects, p_val_projects = stats.ttest_ind(projects_left, projects_stayed, equal_var=False)

print("T-test удволетворенности:", t_stat_satisfaction, ", p-value:", p_val_satisfaction)
print("\nT-test кол-во проектов:", t_stat_projects, ", p-value:", p_val_projects)

# график распределения вероятностей по удволетворенности и числа проектов от увольнений
plt.figure(figsize=(7,5))
sns.boxplot(x='left', y='satisfaction_level', data=df)
plt.title('сравнение удволетворенности')
plt.xticks([0,1], ['оставшиеся', 'уволившиеся'])
plt.show()

plt.figure(figsize=(7,5))
sns.boxplot(x='left', y='number_project', data=df)
plt.title('сравнение чиисла проектов')
plt.xticks([0,1], ['оставшиеся', 'уволившиеся'])
plt.show()

"""Задача 9. Разделить данные на тестовую и обучающую выборки
Построить модель LDA, предсказывающую уволился ли
сотрудник на основе имеющихся факторов (кроме department и
salary)
Оценить качество модели на тестовой выборки
"""

from sklearn.model_selection import train_test_split
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, roc_auc_score

# подготовка данных
x = df.drop(columns=['left', 'department', 'salary'])
y = df['left']

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=40)

# LDA
lda = LinearDiscriminantAnalysis()
lda.fit(x_train, y_train)
y_pred = lda.predict(x_test)

#выводим оценку
print("коэф точности:", accuracy_score(y_test, y_pred))
print("\n\nкачество классификаторов\n\n", classification_report(y_test, y_pred))
print("\nматрица ошибок\n\n", confusion_matrix(y_test, y_pred))

#roc и auc
y_prob = lda.predict_proba(x_test)[:, 1]
fpr, tpr, thresholds = roc_curve(y_test, y_prob)
auc_score = roc_auc_score(y_test, y_prob)

plt.figure(figsize=(7,6))
plt.plot(fpr, tpr, label=f'AUC = {auc_score:.2f}')
plt.plot([0,1], [0,1], 'k--')
plt.xlabel('Частота ложноположительных результатов')
plt.ylabel('Истинно положительный показатель')
plt.title('roc-кривая')
plt.legend()
plt.show()

#оценка качества модели
from sklearn.model_selection import cross_val_score

scores = cross_val_score(lda, x, y, cv=5, scoring='accuracy')
print("кросс валидация:", scores)
print("\nсреднее значение:", scores.mean())

#lda
x_lda = lda.transform(x_test)

plt.figure(figsize=(7,5))
plt.scatter(x_lda[:,0], np.zeros_like(x_lda[:,0]), c=y_test, cmap='coolwarm', alpha=0.6)
plt.title('проекция на lda')
plt.xlabel('LDA')
plt.show()